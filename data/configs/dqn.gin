# basic params
get_train_loop.alg_name='dqn'
TrainLoop.root_dir='/srv/bachmann/data/dqn'
TrainLoop.eval_interval = 3000
TrainLoop.num_eval_episodes = 9
TrainLoop.log_interval = 600
TrainLoop.collect_raw = True # TODO warn

Loop.sampling_rate=0.25
RulePerformanceTable.metric='fpr'
RulePerformanceTable.use_cache=True
RulePerformanceTable.cache_class=@PerformanceTrackingWorstOffenderCache
PerformanceTrackingWorstOffenderCache.metric='fpr'
PerformanceTrackingWorstOffenderCache.capacity='inf'

# state
TrainLoop.use_prev_action_as_obs=False
TrainLoop.state_obs_selection=(@TrafficSituation(),)

# action
TrainLoop.action_space_selection=@DqnMinPrefLenActionSpace() #@DqnRejectionActionSpace()

# reward
HHHEnv.reward_calc=@MultiplicativeRewardNew()
MultiplicativeReward.precision_weight=0
MultiplicativeReward.recall_weight=1.5
MultiplicativeReward.fpr_weight=3
MultiplicativeReward.bl_weight=0.26

# trace settings
DistributionTrace.traffic_trace_construct = @T6
T4.num_benign=500
T4.num_attack=300
Loop.action_interval=10

# generic params
DQNWrapAgent.lr=5e-5
DQNWrapAgent.lr_decay_rate=0.96
DQNWrapAgent.lr_decay_steps=1000
DQNWrapAgent.eps_greedy=1.0
DQNWrapAgent.eps_greedy_end=0.0
DQNWrapAgent.eps_greedy_steps=75000
TrainLoop.gamma=0
TrainLoop.num_iterations = 150000
TrainLoop.batch_size = 64
TrainLoop.replay_buf_size = 150000
TrainLoop.initial_collect_steps = 1200
TrainLoop.log_interval = 600

# NN
DQNWrapAgent.use_rnn=True
TrainLoop.train_sequence_length=10
DQNWrapAgent.rnn_input_layers=(200, 200)
DQNWrapAgent.rnn_lstm_size=(128, 128, 128)
DQNWrapAgent.rnn_output_layers=(200,)
DQNWrapAgent.batch_norm=True

# CNN parameters
include '/home/bachmann/test-pycharm/data/configs/cnn.gin'
DQNWrapAgent.cnn_spec=%cnn_128_multi
DQNWrapAgent.cnn_act_func=@tf.keras.activations.relu
